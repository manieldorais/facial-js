<!DOCTYPE html>
<html lang="pt-BR">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Reconhecimento Facial em Tempo Real</title>
    
    <script src="https://cdn.jsdelivr.net/npm/face-api.js/dist/face-api.js"></script> 
    
    <style>
        /* Melhorias de Estilo */
        body { font-family: sans-serif; text-align: center; padding: 20px; background-color: #f4f4f4; }
        .container { 
            max-width: 800px; 
            margin: 0 auto; 
            padding: 20px; 
            background-color: white; 
            border-radius: 10px; 
            box-shadow: 0 4px 12px rgba(0,0,0,0.1); 
        }
        
        #video-container { 
            position: relative; 
            display: inline-block; 
            margin-top: 20px;
            /* CHAVE: Limita o container ao tamanho m√°ximo para que o v√≠deo se ajuste */
            max-width: 100%; 
            width: 100%; /* Garante que o container ocupe todo o espa√ßo dispon√≠vel */
        }
        #inputVideo {
            display: block;
            /* CHAVE: Faz o v√≠deo ser responsivo */
            width: 100%; 
            height: auto;
            border: 4px solid #333;
            border-radius: 8px;
        }
        #overlayCanvas {
            position: absolute;
            top: 0;
            left: 0;
            /* CHAVE: Garante que o canvas se ajuste ao v√≠deo */
            width: 100%; 
            height: 100%; 
        }
        #status { 
            margin-top: 20px; 
            padding: 15px;
            font-size: 1.2em; 
            font-weight: bold; 
            border-radius: 6px;
            transition: background-color 0.3s;
            min-height: 25px; /* Para evitar pulo de tela ao mudar o texto */
        }
        #threshold-info { font-size: 0.9em; color: #555; margin-bottom: 15px; }
    </style>
</head>
<body>

    <div class="container">
        <h1>üé• Verifica√ß√£o Facial com C√¢mera</h1>

        <p id="threshold-info">
            Toler√¢ncia de Correspond√™ncia (Threshold): 0.6.
        </p>
        
        <div id="video-container">
            <video id="inputVideo" autoplay muted></video>
            <canvas id="overlayCanvas"></canvas>
        </div>

        <div id="status">Iniciando carregamento...</div>
    </div>

    <script>
        const video = document.getElementById('inputVideo');
        const canvas = document.getElementById('overlayCanvas');
        const statusElement = document.getElementById('status');
        
        const DISTANCE_THRESHOLD = 0.6; 
        let labeledFaceDescriptors = null; 
        let displaySize;
        let analysisInterval = null; 

        /**
         * Carrega os modelos de Machine Learning e processa a imagem de refer√™ncia.
         */
        async function loadModelsAndReference() {
            // ... (Fun√ß√£o inalterada, pois o problema n√£o estava aqui)
            try {
                statusElement.innerText = "Carregando modelos de ML...";
                
                await faceapi.nets.ssdMobilenetv1.loadFromUri('https://raw.githubusercontent.com/justadudewhohacks/face-api.js/master/weights');
                await faceapi.nets.faceLandmark68Net.loadFromUri('https://raw.githubusercontent.com/justadudewhohacks/face-api.js/master/weights');
                await faceapi.nets.faceRecognitionNet.loadFromUri('https://raw.githubusercontent.com/justadudewhohacks/face-api.js/master/weights');
                
                statusElement.innerText = "Modelos carregados. Buscando refer√™ncia (./referencia.jpg)...";

                const referenceImage = await faceapi.fetchImage('./referencia.jpg'); 
                const referenceDetection = await faceapi.detectSingleFace(referenceImage).withFaceLandmarks().withFaceDescriptor();

                if (!referenceDetection) {
                    statusElement.innerText = "üö® Erro: N√£o detectei face na imagem de refer√™ncia (referencia.jpg). Verifique o arquivo.";
                    statusElement.style.backgroundColor = '#ffdddd';
                    return;
                }

                labeledFaceDescriptors = new faceapi.FaceMatcher(
                    new faceapi.LabeledFaceDescriptors('Pessoa Conhecida', [referenceDetection.descriptor]),
                    DISTANCE_THRESHOLD
                );

                statusElement.innerText = "Refer√™ncia pronta. Iniciando c√¢mera...";
                statusElement.style.backgroundColor = '#ddffdd';

                startVideo();

            } catch (error) {
                console.error("Erro ao carregar:", error);
                statusElement.innerText = "üö® ERRO CR√çTICO: N√£o foi poss√≠vel iniciar. Certifique-se de estar rodando em um servidor local.";
                statusElement.style.backgroundColor = '#ffdddd';
            }
        }

        /**
         * Inicializa o stream de v√≠deo da c√¢mera.
         */
        function startVideo() {
            // ... (Fun√ß√£o inalterada)
            navigator.mediaDevices.getUserMedia({ video: {} })
            .then(stream => {
                video.srcObject = stream;
            })
            .catch(err => {
                console.error("Erro ao acessar a c√¢mera:", err);
                statusElement.innerText = "üö® ERRO: Acesso √† c√¢mera negado ou indispon√≠vel. Permita o acesso e recarregue.";
                statusElement.style.backgroundColor = '#ffdddd';
            });
        }
        
        /**
         * CORRE√á√ÉO PRINCIPAL: Define as dimens√µes reais do canvas com base no v√≠deo.
         */
        video.addEventListener('loadedmetadata', () => {
            // 1. Define as dimens√µes internas do canvas (resolu√ß√£o da c√¢mera) para o face-api.js
            // Usamos as dimens√µes nativas do stream para os c√°lculos internos do face-api,
            // mas o CSS cuida do redimensionamento visual do elemento.
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;

            // 2. Define o displaySize para o resizeResults (face-api.js)
            // Neste ponto, ainda usamos o nativo, mas a corre√ß√£o de responsividade vir√° no evento 'play'
            displaySize = { width: video.videoWidth, height: video.videoHeight };

            // O matchDimensions √© importante para a correta inicializa√ß√£o do face-api.js
            faceapi.matchDimensions(canvas, displaySize);
        });

        // Opcional: Recalcular displaySize e canvas em caso de redimensionamento da janela
        window.addEventListener('resize', () => {
            // Se o v√≠deo estiver tocando e os descritores estiverem prontos
            if (video.paused === false && labeledFaceDescriptors) {
                // Atualiza o displaySize com as dimens√µes ATUAIS do elemento DOM
                displaySize = { width: video.offsetWidth, height: video.offsetHeight };
                
                // Recalcula o dimensionamento do canvas para o face-api.js
                // Usamos as dimens√µes do elemento HTML (offsetWidth/offsetHeight) para isso.
                faceapi.matchDimensions(canvas, displaySize); 
            }
        });


        /**
         * Loop principal para detec√ß√£o e reconhecimento em tempo real.
         */
        video.addEventListener('play', () => {
            if (analysisInterval) {
                clearInterval(analysisInterval); 
            }
            
            // ATUALIZA√á√ÉO CHAVE: Redefine displaySize com as dimens√µes do ELEMENTO visual (DOM)
            // Isso garante que o redimensionamento do face-api.js (resizeResults) 
            // mapeie as caixas para o tamanho vis√≠vel do v√≠deo na tela, e n√£o para a resolu√ß√£o nativa.
            displaySize = { width: video.offsetWidth, height: video.offsetHeight };
            faceapi.matchDimensions(canvas, displaySize);
            
            // Inicia o loop de an√°lise (a cada 100ms)
            analysisInterval = setInterval(async () => {
                
                if (!labeledFaceDescriptors || !displaySize || displaySize.width === 0) {
                    return; 
                }
                
                // 1. Detec√ß√£o e extra√ß√£o de descritores (baseado na resolu√ß√£o nativa do stream)
                const detections = await faceapi.detectAllFaces(video, new faceapi.SsdMobilenetv1Options({ minConfidence: 0.5 }))
                                                 .withFaceLandmarks()
                                                 .withFaceDescriptors();

                // 2. Redimensionamento: Mapeia as detec√ß√µes para o tamanho VIS√çVEL do canvas (displaySize)
                const resizedDetections = faceapi.resizeResults(detections, displaySize);
                
                // 3. Limpeza do Canvas
                canvas.getContext('2d').clearRect(0, 0, canvas.width, canvas.height);

                // --- 4. Processamento de Reconhecimento ---
                if (resizedDetections.length > 0) {
                    resizedDetections.forEach((detection) => {
                        const bestMatch = labeledFaceDescriptors.findBestMatch(detection.descriptor);
                        // A caixa j√° est√° mapeada para as dimens√µes vis√≠veis (displaySize)
                        const box = detection.detection.box; 

                        let resultText = '';
                        let boxColor = 'red';

                        if (bestMatch.label === 'Pessoa Conhecida' && bestMatch.distance <= DISTANCE_THRESHOLD) {
                            resultText = `‚úÖ ${bestMatch.label} (${bestMatch.distance.toFixed(2)})`;
                            boxColor = 'green';
                            statusElement.innerText = `‚úÖ Match Encontrado! Dist√¢ncia: ${bestMatch.distance.toFixed(3)}`;
                            statusElement.style.backgroundColor = '#d4edda';
                            video.pause(); 
                            // IMPORTANTE: Se pausar, limpa o loop para economizar CPU
                            if (analysisInterval) {
                                clearInterval(analysisInterval); 
                                analysisInterval = null;
                            }
                            return; 
                        } else {
                            resultText = `‚ùå Desconhecido (${bestMatch.distance.toFixed(2)})`;
                            boxColor = 'red';
                            statusElement.innerText = `‚ùå Pessoa N√£o Reconhecida. Dist√¢ncia: ${bestMatch.distance.toFixed(3)}`;
                            statusElement.style.backgroundColor = '#f8d7da';
                        }
                        
                        // Desenha a caixa delimitadora no canvas
                        const drawBox = new faceapi.draw.DrawBox(box, { label: resultText, boxColor: boxColor });
                        // √â crucial que o drawBox desenhe no canvas, que agora tem o tamanho correto.
                        drawBox.draw(canvas);
                    });
                } else {
                    statusElement.innerText = "Procurando faces...";
                    statusElement.style.backgroundColor = '#fff3cd'; /* Corrigido para amarelo mais claro */
                }

            }, 100); 
        });


        // PONTO DE INICIALIZA√á√ÉO SEGURO
        window.onload = loadModelsAndReference;

    </script>

</body>
</html>